[["index.html", "A Primer of Ecosystem Modeling - a work in progress 1 Prerequisites 1.1 Must do’s 1.2 A couple of useful citations", " A Primer of Ecosystem Modeling - a work in progress Hank Stevens, BIO 672 2021-02-05 1 Prerequisites For this R primer, you’ll need to read several chapters of Soetaert and Herman (2009) which are available on the Canvas website. Their book is an excellent source for those interested in ecosystem modeling, especially in aquatic systems. We will use bits of it along with this online text to get a little more comfortable with ecosystem processes and models. I also assume that you are reading a book on ecosystem ecology such as Chapin III, Matson, and Vitousek (2011). 1.1 Must do’s Read background material as needed. Install or update R (4.0.3, as of Jan 2021) Install or update RStudio Install select R packages: ‘deSolve,’ ‘tidyverse,’ ‘LakeMetabolizer`, ’lubridate’ Also, before doing most tasks in this primer, load deSolve and tidyverse with library(deSolve); library(tidyverse). The R working directory is the place R automatically looks for files. For simplicity, I will refer to the R working directory as Rwork. Therefore, Rwork/data would be a folder or directory called data inside Rwork. At any point in time, you can find out what your working directory is using getwd(). You can set your working directory using setwd(\"HD/MyStuff/Rwork\"), where “HD/MyStuff/Rwork” is the path to what you want your working directory to be. You can also use the “Session” pull-down menu in RStudio. 1.2 A couple of useful citations Ten simple rules for biologists learning to program. PLoS Computional Biology 14(1): e1005871. https://doi.org/10.1371/journal.pcbi.1005871 Ten simple rules for tackling your first mathematical models: A guide for graduate students by graduate students. PLOS Computational Biology 17(1): e1008539. https://doi.org/10.1371/journal.pcbi.1008539 "],["intro.html", "2 Introduction ecosystem models 2.1 Why models? 2.2 What’s an ecosystem? 2.3 What’s a model? 2.4 Steps in modeling 2.5 An example in R", " 2 Introduction ecosystem models Reading: pp. 1-17, (in Chapters 1, 2 of Soetaert and Hermann 2009) In this course, we’ll cover the very basics of ecosystem modeling. There are several goals I have for you, the reader. I hope the you, become more fluent in the discipline of ecosystem ecology; that you understand and can use basic terminology, and can identify quantitative pieces of the literature you read, and presentations you hear and see; understand and describe the quantitative and qualitative features of ecosystem dynamics and models of those dynamics; assess the relative merits of different modeling approaches and different mathematical formalisms of those approaches; create models of ecosystem dynamics of your own; write R code to implement ecosystem models. To do all this, the following text relies heavily on selected secondary sources especially Soetaert and Herman (2009). I also cite selected primary soruces where appropriate. 2.1 Why models? In general, models are simplifications of reality. Useful models capture something useful about the reality we are interested in. A road map is a useful model of a road network. It captures just what we need. We model to aid understanding, because, at some level, the model is a quantitative and qualitative explanation for some phenomenon (Fig. 2.1). We can use models to test hypotheses, guide experiments, and predict manage ecosystems and populations (Soetaert and Herman 2009). Figure 2.1: We use conceptual and mathematical models to interpret reality. (Fig. 1.3 in Soetaert and Hermann, 2009). 2.2 What’s an ecosystem? You can find definitions of an ecosystem elsewhere, but here we want to emphasize the abstraction of that ecosystem (Fig. 2.2). We will think of an ecosystem as a set of one or more compartments containing some mass of an element of interest, such as carbon or nitrogen. That element is the currency of the ecosystem. These compartments (aka pools, stocks) are connected by fluxes, or flows, the transfer of some mass of the element. When these transfers come from outside the ecosystem entirely, we refer to them as imports. When the transfer exits the system entirely, we refer to it as an exports. Figure 2.2: An ecosystem perspective of lake, in terms of phosphorus (Carpenter et al. 1992). Boxes are ecosystem compartments and the quantities are pools (a.k.a. stocks, units are mass per unit area or volume). Arrows are fluxes (units are mass per unit time. Ecosystem fluxes or flows are influenced by state factors such as temperature, time, or disturbance which act as constraints that can limit or speed up the fluxes or determine the current states of the variables (Fig. 2.3). Figure 2.3: The current state of an ecosystem depends on state factors (Chapin III, Matson, and Vitousek 2011). We can describe an ecosystem as a set of pools or compartments, connected by fluxes, that is, transfers of energy or materials among pools. In Fig. 2.2, all pools are receiving imports from outside the system, represented by arrows coming from the amorphous cloud. All pools save dissolved P appear to export P back out. Dissolved P is receiving fluxes from all the animals in the system, and losing P to seston, which is primarily phytoplankton. 2.3 What’s a model? You’ve already seen ecosystem models. An ecosystem model consists of the compartments and fluxes we saw above. We refer to the currencies in different compartments as variables because they can vary or change through time. We use mathematical equations and computational controls to represent fluxes between compartments. In the equations, there are constants that we call parameters that control the rate of these fluxes. We describe an ecosystem using balance equations for each pool (p. 18, Soetaert and Herman 2009). A balance equation is simply a bookkeeping or budgeting device to keep track of fluxes: \\[\\mathrm{Change~in~pool} = \\mathrm{Sources - Sinks}\\] As models increase in complexity, we usually use differential equations, or time derivatives, to represent the balance equation for each pool or state variable in a model. For instance, the dissolved P in Fig. 2.2 might look like \\[\\frac{dD}{dt} = I + e_HH + e_N N + e_1 F_1 + e_2 F_2 - u_SS\\] where \\(D\\) is the amount of P in the dissolved pool, perhaps in mg\\(\\cdot\\)m\\(^{-2}\\), \\(I\\) is import, or source, from outside the system (dust? lake inflow?), and \\(H\\), \\(N\\), \\(F_1\\), and \\(F_2\\) are the other pools. The lower case letters are parameters or rate constants that are the mass-specific fluxes. The units of \\(dD/dt\\) are mg\\(\\cdot\\)m\\(^{-2}\\cdot\\)d\\(^{-1}\\), and so each term (e.g., \\(I\\) or \\(e_H H\\)) in the equation must also have these same units. units of \\(e_H H\\) must be mg\\(\\cdot\\)m\\(^{-2}\\)\\(\\cdot\\)d\\(^{-1}\\). units of \\(H\\) are mg\\(\\cdot\\)m\\(^{-2}\\). Ergo, units of \\(e_H\\) are d\\(^{-1}\\). More intuitively, the units of these rate constants are mg\\(\\cdot\\)m\\(^{-2}\\cdot\\)d\\(^{-1}\\) per mg\\(\\cdot\\)m\\(^{-2}\\) in the lake. Note the quantities cancel out, and we are left with d\\(^{-1}\\). See Soetaert and Herman (2009) section 2.1.4 for further explanation. One nice feature of ecosystem ecology and ecosystem models is the emphasis on the conservation of mass and energy. We aim to track where everything comes from and where it goes. If we add up all of the rates of change for each pool, we should see that most of them cancel out, and we are left with only imports and exports. Doing this summation will tell us whether our model makes sense or we made a mistake. If we did not make any mistakes, it will tell us whether the entire system is a net sink or source of our currency. For instance, after simplifying the lake ecosystem model, we would have, \\[\\frac{dD}{dt} + \\frac{dS}{dt} + \\frac{dH}{dt} + \\frac{dN}{dt} + \\frac{dF_1}{dt} + \\frac{dF_2}{dt} = \\ldots \\ldots = \\mathrm{Imports - Exports}\\] See Soetaert and Herman (2009) section 2.1.3 for further explanation. State factors also enter into the model, typically altering the fluxes. For instance, increasing atmospheric temperature might force a predictable change in our rate constants (e.g., \\(e_H\\), \\(u_S\\)) in the above model. Because temperature is an external factor forcing a change to a parameter, we often call its role in a model a forcing function. We will add temperature to a model later in the book. To review: variables are quantities that change with time, such as the amount of carbon in the atmosphere, or the amount of phosphorus in the primary producers in a lake. Parameters are (typically) constants in equations that quantify how quickly the variables change. Forcing functions represent state factors that we think of as external to the ecosystem compartments. No models apply everywhere, all the time. All models are limited for a specific domain and with specific boundaries. These are the spatial, temporal and conceptual limits on a model. 2.3.1 Other ideas Statistical models (e.g., regression) are concerned with describing patterns and hypothesis testing. Process models (e.g., stock and flow models) are also descriptions of natural systems, but they include more mechanism and seek to describe mechanism and understand process. People sometimes call these mechanistic models. Figure 2.4: A statistical model of aboveground plant biomass as a function of available soil nitrogen. A theory is a well supported hierarchical framework that contains clearly formulated postulates, based on a minimal set of assumptions, from which a set of predictions logically follows (Marquet et al. 2014). Efficient theory is based to as much as possible on first principles, and relies on as few assumptins as possible. In contrast to theory, models are specific implementations of theory and specific descriptions of nature. Remember that in principle, all models are wrong, but some are useful1. Exercise: Ask yourself whether a lake is a carbon sink or a source. Draw an appropriate compartment model to address this question. After having done so, ask yourself what assumptions you’ve made about the temporal and spatial scales. What mechanisms have you included? Why? 2.4 Steps in modeling Soetaert and Herman (2009) identify a series steps that guides model development and ultimately improve understanding and prediction (Fig. 2.5). Figure 2.5: It is helpful to use a series of steps in improving our models. This was Figure 1.7 in Soetaert and Hermann (2009) but I chopped it in half. Read the left half (top to bottom), then the right half (top bottom). 2.5 An example in R Here we create a simple model to illustrate some of what we’ve been describing. Consider our lake above, as a whole. Just one big pool of P. We’ll let the imports, \\(I\\), be constant and independent of the amount of the P in the lake. Our exports will depend on the amount of the P in the system-the more P in the system, to more can be exported, that is, a constant fraction, \\(a\\), is exported, \\[\\frac{dP}{dt} = I - a P\\] In R, we write a function for the system of differential equations, and include descriptive comments. ## A function called lake to represent an ODE ## to use in ode() in the deSolve package. lake &lt;- function( time, state_vars, parameters ){ ## ODE function for a single pool (e.g., a lake) with a constant ## rate of import, and first-order export function (depends on the pool). ## The arguments time, state_vars, and parameters will be used by ode() ## to solve (numerically integrate) the system. ## I is the constant input rate ## a is the constant mass-specific loss rate ## P is the state variable P &lt;- state_vars[1] # state variable(s) with(as.list(parameters), # tell R to look inside &#39;parameters&#39; { dP.dt &lt;- I -a*P # the balance eq. or rate func. return(list(dP.dt)) # return the value of the rate function }) } Next, we tell R what the values of the parameters are that we want. Let’s say the the import is 3 mg\\(\\cdot\\)m\\(^{-2}\\cdot\\)d\\(^{-1}\\), and that the fraction (or rate, really) is 0.5 d\\(^{-1}\\), or more intuitively, mg\\(\\cdot\\)m\\(^{-2}\\cdot\\)d\\(^{-1}\\) per mg\\(\\cdot\\)m\\(^{-2}\\) in the lake. Note the quantities cancel out, and we are left with d\\(^{-1}\\). ## parameters p &lt;- c(I = 10, # constant input rate mg / m^2 / day a = .5 # mass-specific output rate, day^-1 ) Now the exciting part. We tell R our starting point and what time points we want to integrate for, and then solve the differential equation and have R return the result for the time points we want. After that, we display the first five time points. initial.state &lt;- c(P=1) # Initial concentration of P in the lake t &lt;- seq(from=0, to=10, by=1/24) # 10 days, in hourly increments ## solve the equation in func, using parameter values in p, ## starting at &#39;initial.state&#39; and return the time points t out &lt;- ode(y=initial.state, times = t, func = lake, parms = p) ## display the first five rows of the solution out[1:5,] ## time P ## [1,] 0.00000000 1.000000 ## [2,] 0.04166667 1.391740 ## [3,] 0.08333333 1.775400 ## [4,] 0.12500000 2.151151 ## [5,] 0.16666667 2.519155 Pictures are informative, so here we plot the result. ## simple graph of the time series plot(out) We can also use ggplot2 to make a pretty graph, and then save it. out2 &lt;- as.data.frame(out) # re-classify the data set ggplot(data=out2, aes(x=time, y=P)) + geom_line() ggsave(&quot;myLake.png&quot;, height=4, width=4) In very simple situations, we can solve the equilibrium by hand. By definition, the equilibrium is a state at which the system stops changing, that is, its rate of change is zero. To find a value of \\(P\\) which is an equilibrium, we set the balance equation equal to zero, and solve for \\(P\\): \\[\\frac{dP}{dt} = 0 = I -aP\\] \\[P^* = \\frac{I}{a}\\] By convention, we denote the equilibrium value of \\(P\\) with an asterisk, or “star,” as in “P-star.” We call this the analytical solution. Questions: Is our graph consistent with the analytical prediction of \\(P^*\\)? Determine the units of \\(I\\) and \\(a\\); show your work and explain it to your cat. In more complex systems, we often (typically?) can’t solve for the analytical solution. Instead, we usually run a model for a long period of time, until the state variables stop changing to find the same result. Alternatively, if we have a model of a real ecosystem, we made be interested in its short term dynamics and address any number of questions related to experimental results, making predictions about the consequences of landscape management, or or using a time series to compare different models. Box, G. E. P. (1979), “Robustness in the strategy of scientific model building,” in Launer, R. L.; Wilkinson, G. N., Robustness in Statistics, Academic Press, pp. 201–236.↩︎ "],["N.html", "3 Describing a nitrogen budget 3.1 Getting started 3.2 Mathematical forms 3.3 Paramaterization 3.4 Mathematical solution 3.5 Add self-limitation", " 3 Describing a nitrogen budget Background Readings: pp. 17-35 (Soetaert and Hermann 2009) Bormann et al. 1977 Figure 3.1: Nitrogen budget for a temperate northern hardwood forest (Hubbard Brook Watershed 6, Bormann et al. 1977). Figure 3.2: A simpler compartment model for Hubbard Brook Watershed 6, based on Bormann et al. (1977). 3.1 Getting started (S&amp;H 15-17) For any ecosystem, we want to start with paper and pencil and sketch out the pools and the fluxes that we think are important (see example, Fig. 3.2). Don’t sweat the details yet – you’ll revise it anyway. Go ahead an label the compartments and the fluxes with with both biological and physical processes as well as some simple abstract notation. Write balance equations (S&amp;H, 3, 17-20). For each flux, identify the underlying biological and physical processes. If you don’t completely know, don’t sweat it. Here are the balance equations for Fig. 3.2: Rate of change of vegetation = uptake - exudates and through fall - leaf and root litter loss \\[\\frac{dV}{dt} = f_1 - f_2 - f_3\\] Rate of change in available pool in soil solution = bulk precip + exudates and through fall + net mineralization - uptake - stream export \\[\\frac{dA}{dt} = I_1 + f_2 + f_4 - f_1 - E_1\\] Rate of change in the bound pool = net N fixation + leaf and root litter loss - net mineralization - stream export \\[\\frac{dB}{dt} = I_2 + f_3 - f_4 - E_2\\] Assess the total load or mass budget (S&amp;H, 19-22). For Fig. 3.2, we have \\[\\frac{d\\left(V+A+B\\right)}{dt} = \\frac{dV}{dt} + \\frac{dA}{dt} + \\frac{dB}{dt} = (f_1 - f_2 - f_3) + (I_1 + f_2 + f_4 - f_1 - E_1) + (I_2 + f_3 - f_4 - E_2)\\] \\[\\frac{d\\left(V+A+B\\right)}{dt} = I_1 + I_2 + f_1 - f_1 + f_2 - f_2 + f_3 - f_3 + f_4 - f_4 - E_1 - E_2\\] \\[\\frac{d\\left(V+A+B\\right)}{dt} = I_1 + I_2 - E_1 - E_2\\] From this we see that the total mass budget for this watershed depends simply on import or inputs, and exports or outputs. For each flux, decide which pools directly influence the flux. In a forest, the flux of nitrogen from vegetation to soil will depend enormously on the amount of vegetation present as leaves senesce and fall, fine roots die back, and water leaches nutrients out of leaves and bark. The flux is very unlikely to depend directly on the amount of nitrogen already in the soil. In a lake, the flux of phosphorous from the water column into phytoplankton depends on the amounts of both the amount of phytoplankton and the amount of phosphate in the water at any given instant. For the vegetation pool in Fig. 3.2, we see each flux (\\(f\\)) is a Function (\\(F()\\)) of one or two pools: Uptake: \\(f_1 = F(V,A)\\) Leaf and root litter, and throughfall: \\(f_3 = F(V)\\) Root exudates, and throughfall: \\(f_4 = F(V)\\) Next, we want to represent these fluxes in a mathematical form. 3.2 Mathematical forms A common starting point for dynamics depending on two pools is the law of mass action. This states that the reaction rate is proportional the product of the pools. In the case of plant uptake of N, which depends on the amounts of N in the available pool and the vegetation pool, this would be \\(aVA\\), where \\(a\\) is a proportionality constant. In some circumstances, these pools might also have exponents different than one (\\(aV^1A^1\\)), such as \\(aVA^2\\). This occurs in chemistry when a reaction requires two molecules of “A” for each molecule of “V.” It might occur in ecology if a rate depends differentially on A and B. Using the law of mass action for plant uptake, we will describe the fluxes in the simple N budget above (Fig. 3.2) with the following expressions. \\[\\begin{align} \\frac{dV}{dt} &amp;= a_{1}AV - a_{2}V - a_3 V\\\\ \\frac{dA}{dt} &amp;= I_1 + a_{2}V + a_{4}B - a_{5}A - a_{1}AV\\\\ \\frac{dB}{dt} &amp;= I_2 + a_{3}V - a_{4}B - a_{6}B \\end{align}\\] Take the time to identify each term and think about the biology or physics that might govern each term. 3.3 Paramaterization Parameteriztion is what we call assigning numerical values to mathematical parameters. Here, we find initial estimates for the parameters in our model. We use the literature for this purpose (Bormann, Likens, and Melillo 1977). If we have the data (we do) and relatively simple mathematical forms (we do), it is fairly straightforward to estimate parameters. For instance, we decided that net mineralization would be directly proportional to the size of the organic pool, \\(B\\), that is, \\(F_4 = a_4B\\). To calculate \\(a_4\\), we substitute data where we can, and solve what we need. \\[\\begin{align*} F_2 &amp;= a_4 B\\\\ 69.6 &amp;= a_4 4700 \\\\ a_4 &amp;= \\frac{69.6}{4700}\\\\ a_4 &amp;\\approx 0.015 \\end{align*}\\] We use the same approach for second order equations as well. Table 3.1: Parameters, variables, units and estimates for a simplified model of Bormann et al. (1977). All fluxes (\\(dX/dy\\)) are in units of kg ha\\(^{-1}\\) y\\(^{-1}\\). (Note that calculations should not be included in your final table, but are presented here for comparison to your own calculations.) p.or.V units Estimate \\(A, B, V\\) state variables kg ha\\(^{-1}\\) \\(26, 4700, 532\\) \\(a_1\\), uptake rate by V from A (kg ha\\(^{-1}\\))\\(^{-1}\\) y\\(^{-1}\\) \\(79.6 / (26 \\cdot 532) = 0.0058\\) \\(a_2\\), loss rate from V to A y\\(^{-1}\\) \\((6.6 + 0.8) / 532 = 0.014\\) \\(a_3\\), loss rate from V to B (kg ha\\(^{-1}\\))\\(^{-1}\\) y\\(^{-1}\\) \\((54.2 + 2.7 + 0.1 + 6.2 ) / 532 = 0.00022\\) \\(a_4\\), mineralization y\\(^{-1}\\) \\(69.6 / 4700 = 0.015\\) \\(a_5\\), export from A y\\(^{-1}\\) \\(3.9 /26 = 0.15\\) \\(a_6\\), export from B y\\(^{-1}\\) \\(0.1/4700 = 0.000021\\) \\(I_1\\), bulk precip kg ha\\(^{-1}\\) y\\(^{-1}\\) \\(6.5\\) \\(I_2\\), N fixation kg ha\\(^{-1}\\) y\\(^{-1}\\) \\(14.2\\) Enter parameters into R. params &lt;- c( i1 = 6.5, # precip i2 = 14.2, # fixation a1 = 79.6 / (26 * 532), # uptake a2 = (6.6 + 0.8) / 532, # throughfall and inorganic exudates a3 = (54.2 + 2.7 + 0.1 + 6.2 ) / 532, # litter, throughfall, organic exudates a4 = 69.6 / 4700, # net mineralization a5 = 3.9 /26, # export from available a6 = 0.1/4700 #export from bound ) # close parentheses params ## i1 i2 a1 a2 a3 a4 ## 6.500000e+00 1.420000e+01 5.754772e-03 1.390977e-02 1.187970e-01 1.480851e-02 ## a5 a6 ## 1.500000e-01 2.127660e-05 3.4 Mathematical solution The mathematical solution is the process of making the predictions using our model and our parameters. We solve the model. With simple models, we can sometimes find analytical solutions. For most ecosystem models, we have to solve the models numerically using numerical integration. Here we write a function that includes our system of differential equations. This will allow R to integrate change through time. bormann1 &lt;- function(t, y, p) { # time, vector of state variables and parameters must be in this order # we can use as.list for both the state variables and parameters # a1 = uptake # a2 = loss from veg to avail # a3 = loss from veg to bound # a4 = net mineralization # a5 = export from avail # a6 = export from bound with( as.list( c(y, p) ), { dV.dt &lt;- a1 * A * V - a2 * V - a3 * V dA.dt &lt;- i1 + a2 * V + a4 * B - a1 * A * V - a5 * A dB.dt &lt;- i2 + a3 * V - a4 * B - a6 * B # Here we return a LIST whose first element is the vector of # rates of change for the state variables. The first element must be these rates, # in the same order as the state variables in y # The second element, total, is the total N in the system return(list( c(dV.dt, dA.dt, dB.dt), total = V + A + B ) )}) } Now that we have the function, we tell R what to do with it. We will define the initial state of the system, and then tell R which time point we want it to return. The initial state of the system is the set of starting values for the state variables. We could choose any values, but I select the values given in Bormann, Likens, and Melillo (1977). ## starting values in kg/ha initial.state &lt;- c( V = 532, A = 26, B = 4700) Finally, let’s solve the system, and have R return the first 20 years. time &lt;- 0:20 out &lt;- ode(y = initial.state, times=time, func=bormann1, parms = params) head(out) # the first 6 lines ## time V A B total ## [1,] 0 532.0000 26.00000 4700.000 5258.000 ## [2,] 1 540.7799 25.76598 4708.168 5274.714 ## [3,] 2 548.7920 25.47149 4717.208 5291.472 ## [4,] 3 556.0406 25.21597 4727.013 5308.270 ## [5,] 4 562.6178 24.99710 4737.489 5325.104 ## [6,] 5 568.6085 24.80918 4748.550 5341.968 Use pivot_longer() and ggplot() to make a graph. We use pivot_longer() gather multiple columns into one with a new name (values_to=kg.N), keeping track of the names of the original columns in a new column (names_to=State.var). We can use pivot_wider() if we ever want to spread those columns back out. outL &lt;- out %&gt;% # select the data set as.data.frame() %&gt;% # make sure it is a data frame and not a matrix ## and the rearrange pivot_longer( cols=-time, names_to=&quot;State.var&quot;, values_to=&quot;kg.N&quot;) ## plot the dynamics ggplot(outL, aes(x=time, y=kg.N)) + # select variables to plot geom_line() + # select the form of the graph facet_wrap(~State.var, scale=&quot;free_y&quot;) # separate each state variable and plot each on its on scale. Figure 3.3: Dynamics of a simple N budget, based on Bormann et al. (1977). In some ways, we have been moderately successful in our first pass at converting a purely budgetary model into a dynamic process model. We mimicked total load, and see similar changes through time of all the state variables. Questions to ponder We replicated approximately the N budget of Bormann et al. (1977), but clearly vegetation cannot keep accumulating N indefinitely. What are our next steps? 3.5 Add self-limitation One logical step is to assume that as vegetation eventually gets limited by some factor or resource that is not in our model. If, at first approximation, the vegetation reaches a carrying capacity independent of high resource availability, we can use an approximation suggested by Soetaert and Hermann (2009) for self-limitation, \\[f(X)V\\left(1-\\frac{V}{K}\\right)\\] where \\(f(X)\\) is everything else that regulates mass-specific growth rate. Exercise Include self-limitation in your model of vegetation, estimate \\(K\\), and produce output. Remember that following our template, we have a maximum rate times resource and self limitation, and inhibition. Currently, we have \\[\\frac{dV}{dt} = a_{1}AV - a_{2}V - a_3 V\\] and rearranging, \\[\\frac{dV}{dt} = \\left(a_{1}A - a_{2} - a_3\\right) V\\] If we add self-limitation, we get \\[\\frac{dV}{dt} = \\left(a_{1}A - a_{2} - a_3\\right) V \\left(1-\\frac{V}{K}\\right)\\] where \\(K\\) is the maximum amount of live vegetation that the ecosystem can sustain, in kg,N,ha\\(^{-1}\\). We don’t know exactly what that is yet, but we may be able to get estimates from the literature. For know we can pretend that it is just a bit more than was there in the mid-1970s, say, \\(K=600\\). Now we rewrite the R function with self-limitation. bormann2 &lt;- function(t, y, p) { # time, vector of state variables and parameters must be in this order # we can use as.list for both the state variables and parameters # a1 = uptake # a2 = loss from veg to avail # a3 = loss from veg to bound # a4 = net mineralization # a5 = export from avail # a6 = export from bound with( as.list( c(y, p) ), { dV.dt &lt;- (a1 * A - a2 - a3) * V * (1-V/K) dA.dt &lt;- i1 + a2 * V + a4 * B - a1 * A * V - a5 * A dB.dt &lt;- i2 + a3 * V - a4 * B - a6 * B # Here we return a list whose first element is the vector of # rates of change for the state variables. The first element must be these rates, # in the same order as the state variables in y # The second element is the total N in the system return(list( c(dV.dt, dA.dt, dB.dt), total = V + A + B ) )}) } We can add a new parameter to our vector of parameters, and then solve our new function bormann2 for the same time interval, and plot it. params[&quot;K&quot;] &lt;- 600 ## starting values in kg/ha initial.state &lt;- c( V = 532, A = 26, B = 4700) time &lt;- 0:200 out &lt;- ode(y = initial.state, times=time, func=bormann2, parms = params) outL2 &lt;- out %&gt;% as.data.frame() %&gt;% pivot_longer(cols=-time, names_to=&quot;State.var&quot;, values_to=&quot;kg.N&quot;) ggplot(outL2, aes(time, kg.N)) + geom_line() + facet_wrap(~State.var, scale=&quot;free_y&quot;) Figure 3.4: Dynamics of an N budget, assuming density-dependence in vegetation with a fixed carrying capacity (Bormann et al. 1977). Unlike our first model of this system, we see state variables on curved trajectories and perhaps reaching asymptotes. This makes greater intuitive sense - over the short term, it is the same as the simple N budget shown in Bormann, Likens, and Melillo (1977) and it also shows a reasonable longterm trajectory for the vegetation, and the predicted consequences for the available and bound pools. Save your own R script of ‘bormann2’ Make a new script that contains nothing but the bormann2 function. Copy the block of text where we define it, paste it into a new R script, and save it as bormann2.R. We will use this function in the next section. "],["lake-metabolism.html", "4 Lake Metabolism 4.1 Estimating Productivity 4.2 By hand, in R 4.3 The LakeMetabolizer package", " 4 Lake Metabolism In this chapter, you’ll study how lakes breath. You’ll get real data from Acton Lake, look it, and measure the rate of an inhale and an exhale. You’ll do that by hand, by hand with a spreadsheet, by hand with R, and finally using an R package, LakeMetabolizer, which is designed to do that and much more. 4.1 Estimating Productivity Most cells respire to do the work of growth and maintenance by consuming oxygen and using it as the final electron acceptor when O\\(_2\\) is reduced, creating water. Because individuals comprise cells, and ecosystems comprise individuals, ecosystems respire too, and we can measure their metabolic rate using oxygen consumption and production. We measure ecosystem metabolic rate as net primary productivity which is the difference between gross primary productivity and respiration. Putting all of this in the same units of oxygen allows us to measure the rate, \\[NPP = GPP - R\\] If we assume that water column oxygen is correlated with the rates of photosynthesis, respiration, and net primary production, then we can think of the slopes of oxygen concentration vs. time as rates of respiration and net primary production. If we assume that respiration is constant throughout the 24 h cycle, we calculate GPP as the sum of NPP and R. 4.2 By hand, in R Let’s practice R by importing, wrangling, and graphing data, then calculating slopes and estimating respiration, NPP, and GPP. Start by obtaining data for Acton Lake (acton.csv). Place it inside a folder labelled ‘data’ inside your working directory. Here you read in data and check whether it loaded properly. ## Either change the path name in this function, or ## make sure you have a folder named &#39;data&#39; inside your working directory acton &lt;- read_csv(&quot;data/acton.csv&quot;, ## tell R the format of one of your variables col_types = cols(date_time = col_datetime(format = &quot;%m/%d/%y %H:%M&quot;)), skip = 1# skips the first line of metadata ) summary(acton) ## date_time cum_h O_mg.L ## Min. :2013-06-27 06:15:00 Min. : 0.00 Min. : 4.530 ## 1st Qu.:2013-06-29 00:11:15 1st Qu.: 41.94 1st Qu.: 7.640 ## Median :2013-06-30 18:07:30 Median : 83.88 Median : 8.365 ## Mean :2013-06-30 18:07:30 Mean : 83.88 Mean : 8.607 ## 3rd Qu.:2013-07-02 12:03:45 3rd Qu.:125.81 3rd Qu.: 9.582 ## Max. :2013-07-04 06:00:00 Max. :167.75 Max. :12.700 ## O_perc temp ## Min. : 56.3 Min. :24.60 ## 1st Qu.: 96.4 1st Qu.:25.00 ## Median :107.6 Median :26.10 ## Mean :110.5 Mean :26.12 ## 3rd Qu.:123.2 3rd Qu.:27.10 ## Max. :167.1 Max. :28.10 Let’s check our understanding of lake oxygen dynamics by plotting the time series. Ggplot understands what to do with dates. ggplot(acton, aes(x=date_time, y=O_mg.L)) + geom_path() Figure 4.1: *Oxygen dynamics from Acton Lake. If we want to calculate the slope of the night time oxygen concentration, then we should identify what the endpoints of “day time” are so that we can do analyses on just daylight or nighttime data. Working with times in R is a little tricky, because times and dates, periods, durations, and intervals are inherently tricky. The date_time variable in the original data set contains all the information, and we extra tidbits from it. # determine day/night intervals ## Sunrise morning &lt;- 6.25 ## sunset evening &lt;- 21 acton &lt;- mutate(acton, date = as.factor( format(date_time, &quot;%Y-%m-%d&quot;) ), ## hour decimal format hour.d = as.integer( format(date_time, &quot;%H&quot;)) + as.numeric(format(date_time, &quot;%M&quot;))/60, daytime.d = ifelse(hour.d &gt;= morning &amp; hour.d &lt; evening, hour.d - morning, NA), nighttime.d = ifelse( hour.d &gt;= evening, hour.d-evening, ifelse(hour.d &lt; morning, 24 - evening + hour.d, NA)), daylight = as.factor( ifelse(hour.d &gt;= morning &amp; hour.d &lt; evening, &quot;day&quot;, &quot;night&quot;)) ) The slope of oxygen concentration at night is respiration, \\(R\\). We will pull out one day’s worth of data and make a quick plot of the time series. acton2 &lt;- subset(acton, date_time &gt; &quot;2013-06-27 21:00:00&quot; &amp; date_time &lt; &quot;2013-06-28 06:15:00&quot;) qplot(x = date_time, y=O_mg.L, data=acton2, geom = &quot;path&quot;) Here is what each night looks like. nights &lt;- filter(acton, daylight==&quot;night&quot;) ggplot(nights, aes(x=nighttime.d, y=O_mg.L, colour=date)) + geom_point() + # plot points geom_smooth(method=&quot;lm&quot;, se=FALSE) # fit linear models each night We can calculate the average slope for all nights, forcing a straight line through each night’s data. The estimates of uncertainty and the P values won’t make sense because the data are horribly autocorrelated, but we can rely on the estimates of the coefficients, and the average slope, in particular. ntd &lt;- acton$nighttime.d/24 m.resp &lt;- lm(O_mg.L ~ nighttime.d + date, data=acton) coef(m.resp)[&quot;nighttime.d&quot;] ## nighttime.d ## -0.2004875 The estimate for night.d, -0.2, is our estimate of the respiration rate in mg_O\\(_2\\)/L per hour. We usually report this per day, which would just be 24 times as great, or -4.812 in mg_O\\(_2\\)/L/day. If you would like you could perform similar analyses on a subset of the data. # select the data frame, filter for &#39;date&#39; values within a range of dates acton2 &lt;- acton %&gt;% filter(date %in% c(&quot;2013-06-28&quot;, &quot;2013-06-29&quot;) ) m.resp2 &lt;- lm(O_mg.L ~ night.d + date, data=acton2) 4.3 The LakeMetabolizer package Here we do something similar but in a much more sophisticated way. To estimate the net ecosystem productivity, we need to know, at least, gas exchange rates, equilibrium oxygen saturation, the mixing depth, and the daylight hours. The metab function in LakeMetabolizer calculates GPP, R, and NEP given requisite data. The function can use several different approaches, depending upon what data you have and your quantitative preferences. Here we use the simplest approach, which the authors refer to as simple bookkeeping. First we load the package and then examine the help page for metab.bookkeep. # install.packages(&quot;LakeMetabolizer&quot;, dep=TRUE) library(LakeMetabolizer) ?metab.bookkeep On the help page you learn about how to use this function. Here we walk through the steps for acquiring or making educated guesses about the data we need. ## pick a reasonable gas exchange constant and mixing depth k.gas &lt;- 0.4 z.mix &lt;- 1 # one meter ## code day and night with ones and zeroes irr &lt;- with(acton,{ifelse(daylight==&quot;day&quot;, 1,0)}) ## estimate dissolved oxygen at saturation (equilibrium) ## using the function, o2.at.sat.base() acton &lt;- acton %&gt;% mutate( do.sat=o2.at.sat.base(temp) ) ## create a data frame with just the variables we want. acton.LM &lt;- acton %&gt;% # select data frame mutate(z.mix = z.mix, k.gas = k.gas, irr=irr ) %&gt;% # add 3 variables ## select only some of the columns select(datetime=date_time, do.obs=O_mg.L, do.sat=do.sat, k.gas=k.gas, z.mix=z.mix, irr=irr) %&gt;% as.data.frame() # simplify the data structure (class tbl_df screws things up) Finally, we use metab(method=\"bookkeep\") to estimate GPP, R, and NEP. ## calculate GPP, R, NEP in mg O2 / L / day out &lt;- metab(acton.LM, method=&quot;bookkeep&quot;) ## [1] &quot;Points removed due to incomplete day or duplicated time step: 96&quot; ## [1] &quot;NA&#39;s added to fill in time series: 0&quot; out ## year doy GPP R NEP ## 1 2013 179 6.345054 -4.786770 -0.2392476 ## 2 2013 180 10.741236 -6.051379 2.4460696 ## 3 2013 181 16.144515 -13.116955 -1.9112065 ## 4 2013 182 6.824456 -5.527167 -0.7835609 ## 5 2013 183 5.421310 -3.849978 0.1289339 ## 6 2013 184 -4.466201 4.411346 1.6162349 How does this compare with our previous estimate? "],["npzd-a-simple-aquatic-ecosystem.html", "5 NPZD - a simple aquatic ecosystem", " 5 NPZD - a simple aquatic ecosystem This section relies entirely on pages 49-58 of Soetaert and Herman (2009). Here, I supply the code (‘NPZD_code.R’) from Soetaert and Herman (2009). Your assignment is to make a copy of it, and document heavily it with your own comments. Nearly every line of code should have a comment. Use comments to demarcate different sections of the script. Don’t forget to start with comments about the what the document is, your name, and the source of the model. Turn in your script, and the figure it should generate. Obtain a copy of the file, or copy it from below. library(deSolve) NPZD&lt;-function(t,state,parameters) { with( as.list(c(state,parameters)), { PAR &lt;- 0.5*(540+440*sin(2*pi*t/365-1.4)) din &lt;- max(0,DIN) Nuptake &lt;- maxUptake * PAR/(PAR+ksPAR) * din/(din+ksDIN)*PHYTO Grazing &lt;- maxGrazing * PHYTO/(PHYTO + ksGrazing)*ZOO Faeces &lt;- pFaeces * Grazing Excretion &lt;- excretionRate * ZOO Mortality &lt;- mortalityRate * ZOO * ZOO Mineralisation &lt;- mineralisationRate * DETRITUS Chlorophyll &lt;- chlNratio * PHYTO TotalN &lt;- PHYTO + ZOO + DETRITUS + DIN dPHYTO &lt;- Nuptake - Grazing dZOO &lt;- Grazing - Faeces - Excretion - Mortality dDETRITUS &lt;- Mortality - Mineralisation + Faeces dDIN &lt;- Mineralisation + Excretion - Nuptake list( c(dPHYTO,dZOO,dDETRITUS,dDIN), c(Chlorophyll = Chlorophyll, PAR=PAR, TotalN= TotalN) ) }) } parameters&lt;-c(maxUptake =1.0, # ksPAR =140, # ksDIN =0.5, # maxGrazing =1.0, # ksGrazing =1.0, # pFaeces =0.3, # excretionRate =0.1, # mortalityRate =0.4, # mineralisationRate =0.1, # chlNratio =1) # state &lt;-c(PHYTO =1, # ZOO =0.1, DETRITUS=5.0, DIN =5.0) times &lt;-c(0,365) library(deSolve) out &lt;- as.data.frame( ode(state,times, NPZD, parameters) ) out num &lt;- length(out$PHYTO) # last element state &lt;- c(PHYTO=out$PHYTO[num], ZOO=out$ZOO[num], DETRITUS=out$DETRITUS[num], DIN=out$DIN[num]) times &lt;-seq(0,730,by=1) out &lt;-as.data.frame(ode(state, times, NPZD, parameters)) out.long &lt;- out %&gt;% as.data.frame() %&gt;% pivot_longer(-time, names_to=&quot;State_vars&quot;, values_to=&quot;Value&quot;) ggplot(data=out.long, aes(time, Value)) + geom_line() + facet_wrap(~State_vars, scales=&quot;free_y&quot;) ## provide a unique name for your PNG file ggsave(&quot;myNPZDplot.png&quot;) "],["model-sensitivity.html", "6 Model Sensitivity 6.1 Model Sensitivity 6.2 Local sensitivity 6.3 Assessing sensitivity in a nitrogen budget model", " 6 Model Sensitivity Reading: Chapter 11, Soetart and Herman (2009) Model sensitivity is part of model testing and validation (Soetart and Herman 2009). In this chapter, we assess model sensitivity, that is, the sensitivity of model outcomes to model inputs. Sometimes, those inputs are small perturbations of the state variables, and we often refer to this as local stability analysis. Here, we investigate the sensitivity of model output to the values of parameters we use as input. This is what we do when we calculate the sensitivity of a demographic projection matrix. Stability and sensitivity are, broadly speaking, simply opposites of each other. Stability is the tendency to remain intact, to persist, or return to a steady state, following a perturbation. Ecologists have a large lingua jargona to describe different types of stability. Sensitivity is the degree to which model outputs tend to deviate if one or more of their inputs change. Before we begin, it is worth listing other questions we should ask ourselves about any model. Testing Solution Correctness Is there an analytical solution against which we can check the model output? (Is there known data with which we can compare the output?) Internal Logic Do the state variables remain in their expected range (e.g., biomass &gt;= 0)? If it is a closed system, do the state variables remain at zero if they are all set to zero? Is mass balance preserved? Model Verification and Validity. Our data and model don’t agree. How do we proceed? Are the data accurate and/or precise? Does the structure of the model approximate the important processes? Do the parameter values correspond to actual rates? These are important questions. We would also like to know how certain we need to be about parameter values. Model output can be very insensitive or very sensitive to small changes in the values of model parameters. Sensitivity analysis helps us pinpoint parameters to which model output might be most sensitive, that is, parameters that can have big effects on model outcomes. 6.1 Model Sensitivity How robust or stable is our model to inevitable untruths? Is our model likely to give approximately correct answers given only approximately correct structure and parameters? There are two forms of sensitivities that we can assess: responses to changes in parameters responses to changes in state variables Also, we can assess global or local behavior: Global changes broad, systematic variation in a parameter. permanence - do all state values remain &gt; 0? Local changes responses to very small changes in parameters. responses to very small changes to state variables at equilibria. 6.2 Local sensitivity Here we will assess the local sensitivity to parameters in our model of the Hubbard Brook nitrogen cycle To assess the local sensitivity of our model to parameters, we will use code that does the following: Create a baseline, or reference data set of model output using our original parameter values. To assess long term average behavior, we typically run the model a long time, throw away early transient dynamics. We then consider the remaining output as our baseline. We could also assess short term responses instead, if we had a particular scenario in mind. Create a new parameter set that changes one parameter by a little bit. This deviate, or “little bit,” could be a very small percentage of the original value, or a small fixed value. Rerun the model using the new parameter set, an initial state that is the same as the first state of the baseline. Calculate the “difference” between the baseline and new model outputs at each time step. The difference may take several forms, such as the absolute difference, the difference relative to the original, the squared difference, or others. Summarize the differences across time using the mean or median, or something else. Rinse and repeat steps 1-5, for each parameter in the model. Save the results in a form we can use. The above steps are an example of pseudocode. Pseudocode is a series of steps written in plain language that describe intermediate steps toward achieving some goal. The function we use follows these steps. It relies heavily on code in Chap. 11 of Soetart and Herman (2009). Below I describe arguments of the function. Let’s start by loading it. Obtain a copy of sensitivity.R and put it in an appropriate directory. I use a folder called code. The R function source() runs an R script. ## This script loads a function called, oddly enough, &quot;sensitivity&quot; source(&quot;code/sensitivity.R&quot;) ## ask for the arguments of the function args(&quot;sensitivity&quot;) ## function (y.initial, times, func, parms, burnin = NULL, tiny = 0.001, ## dev.type = &quot;normalized&quot;, summary.type = &quot;arithmetic_mean&quot;) ## NULL Some of the arguments are the same as for ode().Here is a bit of how the function works: y.initial is a named vector the starting point for the ODEs. By ‘named,’ we mean that the elements have names, as in y=c(A=1, B=2). times is the vector of times for which the user wants to assess sensitivity. func is the system of ODEs written for use with ode(). parms is the vector of parameter values used in func. burnin is the number of initial time steps to throw away. NULL causes the function to throw away the first half. Otherwise set an actual number (integer). tiny is the proportional deviation to the parameter (0.1 = 10% increase, -0.1 = 10% decrease). summary.type refers to how the time series of deviates are summarized. The current options are ‘arithmetic_mean,’ ‘mean_absolute’ (the arthmetic means of absolute values of the deviates), or ‘RMSE’ (the root mean squared error). dev.type refers to the type of sensitivity, either the simple ‘deviate’ (dy), ‘sensitivity’ (dy/dp), ‘elasticity’ (d(log[y])/d(log[p])), ‘normalized’ ( [dy/y] / [dp/p]). Default is ‘normalized’ which is nearly identical to ‘elasticity.’ The function returns a named list containing several elements: deviation.summary is data frame of the summarized deviates for each parameter (rows), for each state variable (columns). dev.type is the type of deviate used. summary.type is the type of summary of the time series used. tiny is size of proportional perturbation to parameters sens.list a list of each of the original time series. 6.3 Assessing sensitivity in a nitrogen budget model Consult our previous chapter on the nitrogen budget of Hubbard Brook, watershed 6. If you have not already done so, make a script that contains nothing but the bormann2 function. Copy the block of text where we define it, paste it into a new R script, and save it as bormann2.R. Next we prepare our workspace, by removing extraneous objects. rm( list = ls() ) # delete (remove) everything in the workspace. The next line of code loads and runs a file. ## I put the script in a folder called &#39;code&#39; that resides inside ## my working directory. The following line of code runs the code in ## the script, and the script is located at code/bormann2.R source(&quot;code/bormann2.R&quot;) ## if you want to make sure that it loaded the right thing, type ## bormann2 on your command line, or highlight the word, and run it with ## Control-Enter ## We also load code to calculate the sensitivities, ## and also to create a time series figure of the deviations. source(&quot;code/sensitivity.R&quot;) # sensitivities of all variables source(&quot;code/sens_fig.R&quot;) # graph time series of sensitivity of one variable Next we begin to run it. params &lt;- c( i1 = 6.5, # precip i2 = 14.2, # fixation a1 = 79.6 / (26 * 532), # uptake a2 = (6.6 + 0.8) / 532, # throughfall and inorganic exudates a3 = (54.2 + 2.7 + 0.1 + 6.2 ) / 532, # litter, throughfall, organic exudates a4 = 69.6 / 4700, # net mineralization a5 = 3.9 /26, # export from available a6 = 0.1/4700, #export from bound K=600 ) # close parentheses initial.state &lt;- c(V = 532, A = 26, B = 4700) t &lt;- seq(from = 0, to = 500, by = 1) Next we run the sensitivity analysis. We start with parameters and initial conditions. params &lt;- c( i1 = 6.5, # precip i2 = 14.2, # fixation a1 = 79.6 / (26 * 532), # uptake a2 = (6.6 + 0.8) / 532, # throughfall and inorganic exudates a3 = (54.2 + 2.7 + 0.1 + 6.2 ) / 532, # litter, throughfall, organic exudates a4 = 69.6 / 4700, # net mineralization a5 = 3.9 /26, # export from available a6 = 0.1/4700, #export from bound K=600 ) # close parentheses initial.state &lt;- c(V = 532, A = 26, B = 4700) t &lt;- seq(from = 0, to = 500, by = 1) Next we do the sensitivity analysis. We will start with a graph, often a good place to start. The graph will show the actual deviations that arise when we alter each parameter one at a time by one percent. out &lt;- sens_fig(&quot;A&quot;, y.initial=initial.state, times=0:1000, func=bormann2, parms=params, burnin=0, tiny=0.01, relative=FALSE ) ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ggplot(out, aes(Time, y, colour=Perturbation)) + geom_line() + facet_wrap(~Parameter, scales=&quot;free_y&quot;) Figure 6.1: Observed responses of the available N pool to a one percent change to each parameter. Note two features of these graphs. First, the change due to the system dynamics is relatively large and so obscures the change due the sensitivity. Second, note that sometimes a smaller parameter (here in blue) results in a higher value of the state variable. It might be more informative the (i) focus on model output after it has approach the steady state, and (ii) examine the relative departure from the reference state. Relative change of 1.0 would mean that for a 1% change in a parameter, the state variable would also change by 1%. out &lt;- sens_fig(&quot;A&quot;, y.initial=initial.state, times=0:1000, func=bormann2, parms=params, burnin=500, tiny=0.01, relative=TRUE ) ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ggplot(out, aes(Time, y, colour=Perturbation)) + geom_line() + facet_wrap(~Parameter, scales=&quot;free_y&quot;) Figure 6.2: Relative responses of the available N pool to a one percent change to each parameter. Note big differences in the values of the y-axes. These graphs show that the state variable responds very consistently through time. In systems with more complicated dynamics, that will not always be the case. Next, we can assess each of the state variables and average across time. b1 &lt;- sensitivity(y.initial=initial.state, times=t, func=bormann2, parms=params, dev.type=&#39;normalized&#39;, summary.type=&quot;arithmetic_mean&quot;) ## Peak at the structure of the output str(b1) ## List of 7 ## $ deviation.summary:&#39;data.frame&#39;: 9 obs. of 5 variables: ## ..$ parameters: chr [1:9] &quot;i1&quot; &quot;i2&quot; &quot;a1&quot; &quot;a2&quot; ... ## ..$ V : num [1:9] 3.71e-05 2.92e-05 2.94e-05 -2.01e-07 -2.68e-04 ... ## ..$ A : num [1:9] 0.0648 0.1042 -0.9535 0.0831 0.5228 ... ## ..$ B : num [1:9] 3.79e-05 1.23e-01 3.73e-05 9.81e-06 6.15e-01 ... ## ..$ total : num [1:9] 0.000319 0.110914 -0.004113 0.000371 0.556306 ... ## $ dev.type : chr &quot;normalized&quot; ## $ summary.type : chr &quot;arithmetic_mean&quot; ## $ burnin : NULL ## $ tiny : num 0.001 ## $ parms : Named num [1:9] 6.5 14.2 0.00575 0.01391 0.1188 ... ## ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;i1&quot; &quot;i2&quot; &quot;a1&quot; &quot;a2&quot; ... ## $ sens.list :List of 4 ## ..$ V : num [1:251, 1:9] 0.00 4.51e-06 1.04e-05 1.61e-05 2.32e-05 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:9] &quot;i1&quot; &quot;i2&quot; &quot;a1&quot; &quot;a2&quot; ... ## ..$ A : num [1:251, 1:9] 0 0.0635 0.0654 0.0654 0.0654 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:9] &quot;i1&quot; &quot;i2&quot; &quot;a1&quot; &quot;a2&quot; ... ## ..$ B : num [1:251, 1:9] 0.00 5.70e-08 1.99e-07 8.61e-07 5.71e-06 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:9] &quot;i1&quot; &quot;i2&quot; &quot;a1&quot; &quot;a2&quot; ... ## ..$ total: num [1:251, 1:9] 0 0.000277 0.000286 0.000287 0.000292 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:9] &quot;i1&quot; &quot;i2&quot; &quot;a1&quot; &quot;a2&quot; ... We will use the deviation summary data frame. Next we would like to graph the summaries, for ease of interpretation. b1L &lt;- b1$deviation.summary %&gt;% pivot_longer(cols=&quot;V&quot;:&quot;total&quot;) ggplot(data=b1L, aes(x=parameters, y=value)) + geom_col() + facet_wrap(~name, scales=&quot;free_y&quot;) Figure 6.3: Model output is more sensitive to some parameters than others. In addition, different state variables are respond differently to different parameters. Note that the y-axis differs among the state variables. We can also summarize across state variables, so that we have one effect of each parameter. Here we use just V, A, and B, and calculate the root mean squared error. rmse.SV &lt;- b1$deviation.summary %&gt;% select(V:B) %&gt;% apply(MARGIN=1, function(x) sqrt( x*x / 3 )) SV &lt;- b1$deviation.summary %&gt;% select(V:B) rmse.SV &lt;- t( apply(SV, MARGIN=1, function(x) { m &lt;- mean(x) sq &lt;- (x-m)^2 sqrt( mean( sq )) }) ) rmse &lt;- data.frame(p=b1$deviation.summary$parameters, rmse=as.numeric(rmse.SV)) qplot(p, rmse, data=rmse, geom=&quot;col&quot;) So,…into what should we direct our effort? What data do we want most want to collect? These sensitivities are likely to help us direct our attention where it would be most useful. "],["MEL.html", "7 Multiple Element Limitation 7.1 Rastetter et al. 1997 7.2 Implementing MEL", " 7 Multiple Element Limitation 7.1 Rastetter et al. 1997 Readings: Chapters 1, 2 Bormann, Likens, and Melillo (1977) Rastetter, Agren, and Shaver (1997) Soetaert and Herman (2009), pages … Rastetter and Shaver (1992) proposed a model of multiple-element limitation of vegetation growth (MEL). Rastetter, Agren, and Shaver (1997) extended that to include soil pools. We replicate this here. It is similar to our model of (Bormann, Likens, and Melillo 1977), but now includes both carbon and nitrogen.2 By now, you’ve had some practice working with models, so take a gander at this one (Fig. 7.1). Figure 7.1: Fig. 1 from Rastetter et al. 1997. Variables \\(B\\), \\(E\\), and \\(D\\) elements in vegetation biomass, inorganic form (e.g., soil solution, or atmospheric CO\\(_2\\)), and organic form in soil detritus. Variable \\(V_i\\) is allocation related to nutrient acquistion. \\(U\\) is uptake by vegetation or microbes in detritus (broadly defined), \\(R_N\\) is deposition, and \\(L_N\\) is loss via leaching or denitrification. \\(R\\) is renewal into the inorganic pools. The little triangles or bowties on fluxes refer to some rate-controlling function; \\(B\\) and \\(V\\) exchange information (dotted lines) that influences fluxes. Other terms are explained in the Table below. Figure 7.2: Table 1 (Rastetter et al 1997). MEL uses the parameter \\(A\\) for “acclimation,” which we can think of as compensation by vegetation that is associated with homeostatic responses to resource supply rates that differ from a stoichiometric ideal. Acclimation has a perfectly good meaning in ecophysiology, which is short- to near-term reversible physiological adjustment in response to changing conditions. In MEL, “acclimation” is much broader, and this early version, it means shifts in the relative rates of C and N accumulation in vegetation, resulting in and from changes in the C:N ratio of vegetation. This occurs due to the ratio of wood to non-woody tissue, defined by \\(q\\). Compensatory dynamics by vegetation, or “acclimation,” is a very important part of this model. “Vegetation” is a complex adaptive system that undergoes diverse changes across many time scales. This could happen through physiological, ecological, and evolutionary changes in plant species composition, ratios of root, stem, leaves and reproductive structures, or changes in tissue C:N ratios. “Acclimation” covers a range of responses with very different time scales, and the variable \\(A\\) is how these changes are incorporated into this ecosystem model. In a later section, we explore the meaning and implications of MEL acclimation. In MEL, vegetation “acclimates” through differential allocation to carbon vs. nitrogen uptake functions. Rastetter et al. refers to this as uptake “effort.” They use this anthropomorphic term “effort” for a pattern of allocation, as in “…increasing uptake effort to acquire limiting soil nutrients.” MEL uses the state variables, \\(V_C\\) and \\(V_N\\), to represent this “effort” or allocation of uptake of C and N respectively. In a later section, we explore the meaning and implications of MEL effort. Both vegetation and microbes acclimate in MEL, in a manner inversely proportion to the relative concentrations of nutrients. In both vegetation and microbes, this results in a tendency toward maintenance of optimal C:N ratios. However, the model handles them differently. It assumes that the acclimation in vegetation is slow while the acclimation in microbes is instantaneous. Here we write out the model nearly as written in Rastetter et al. (1997), but with some reordering. By default, R is an interpreted language rather than a compiled language. What that means for us is that R processes commands one line at a time. Therefore, if a function F requires parameter x, we have to make sure parameter x is defined before we define F. In our implementation of MEL below, Mc requires Ucm, so Ucm needs to be defined before Mc. Copy this into a new script and name it ‘mel2.R.’ In that script, add more comments to those I started. When you save that script, you can use source('mel2.R') to load the function. mel2 &lt;- function(time, y, p){ with(as.list(c(y,p)), { ## Carbon is 1 and Nitrogen is 2 in ## E - inorganic; D - soil organic w/ microbes; B - veg biomass; ## V - acclimation ## Fig. 1 of Rastetter et al. (1997) ## Gross UPTAKE of inorganic nutrients by Microbes ## Note rearrangement of terms (cf. Rastetter et al. 1997) ## (uptake) X (carbon availability) X (stoichiometric optimization) Unm &lt;- alpha_n*En/(k_nm + En) * psi*Dc * Dc/(theta*Dn) Ucm &lt;- alpha_c*Ec/(k_cm + Ec) * psi*Dn * (theta*Dn)/Dc # alpha_c=0 ## Microbial consumption ## nutrient availability + gross uptake Mc &lt;- psi*Dc + Ucm Mn &lt;- psi*Dn + Unm Alpha_c &lt;- epsilon_c * theta*Mn/(Mc + theta*Mn) Alpha_n &lt;- epsilon_n * Mc/(Mc + theta*Mn) ## C:N ratio (units of C) q &lt;- q_w*Bc/(k_q + Bc) ## SURFACE area related to nutrient acquisition (0 &lt; z &lt; 1) Sc &lt;- (Bc + q*Bn)^zc Sn &lt;- (Bc + q*Bn)^zn ## UPTAKE by Vegetation ## uptake constant X rel. effort X Surface area X resource conc. Ucv &lt;- gc * Vc * Sc * Ec/(kc + Ec) Unv &lt;- gn * Vn * Sn * En/(kn + En) ## LOSSES Lcv &lt;- mc*Bc Lnv &lt;- mn*Bn Lce &lt;- beta_ce * Ec # beta_ce = 0 # export = 0 Lne &lt;- beta_ne * En # leaching or denitrification Lcd &lt;- beta_d * Dc Lnd &lt;- beta_d * Dn ## REPLENISHMENT to the inorganic pools (R) Rcm &lt;- Mc*(1-Alpha_c) # C respiration Rnm &lt;- Mn*(1-Alpha_n) # N mineralization Rcv &lt;- rc*Bc Rnv &lt;- rn*Bn ## Available elemental nutrients ## Set dE_i/dt = 0 to control the inorganic pools externally dE_N &lt;- Rne + Rnm + Rnv - Lne - Unm - Unv ## dE_C &lt;- Rce + Rcm + Rcv - Lce - Ucm - Ucv dE_C &lt;- 0 ## Nutrients in vegetation BIOMASS dB_C &lt;- Ucv - Rcv - Lcv dB_N &lt;- Unv - Rnv - Lnv ## Nutrients in DETRITUS dD_C &lt;- Lcv + Ucm - Lcd - Rcm dD_N &lt;- Lnv + Unm - Lnd - Rnm ## Acclimation (compensation) potential ## mass-specific growth rates Grc &lt;- dB_C/Bc Grn &lt;- dB_N/Bn ## symmetric C:N differential plus relative growth difference A &lt;- log(Bc/(q*Bn)) + tau * (Grc - Grn) ## Relative effort toward compensation ## if(A&gt;0) Vstar &lt;- Vc else Vstar &lt;- Vn Vstar &lt;- (A &gt; 0) * Vc + (A &lt; 0) * Vn dV_C &lt;- -1*a*A*Vstar dV_N &lt;- -1 * dV_C ## Auxiliary ecosystem variables NPP &lt;- Ucv - Rcv Net_N_uptake &lt;- Unv - Rnv Ecosystem_N=Bn+En+Dn Ecosystem_C=Bc+Ec+Dc return(list(c(dE_C, dE_N, dB_C, dB_N, dD_C, dD_N, dV_C, dV_N), NPP=NPP, Net_N_uptake=Net_N_uptake, Ecosystem_C=Ecosystem_C) ) }) } Here we start with a vector of model parameters whose description and units are found in Table 1 above. The numeric values come from Table 2 in Rastetter et al. (1997). You should copy these into your own script, and then add your own comments to each parameter, as I started to. ## Parameter set for a closed ecosystem p.c &lt;- c( # carbon, nitrogen Rce=0, Rne=0, # no renewal from outside the ecosystem gc=1116, gn =23.77, rc=0.02055, rn=0.01955, mc=0.02055, mn=0.08009, kc=350, kn=5, zc=0.11, zn=0.16, epsilon_c=0.6, epsilon_n=0.6471, alpha_c=0, alpha_n = 0.01092, k_cm = 1, k_nm=1, beta_ce = 0, beta_ne = 0, # Other a=5, tau=3, # damping coef q_w=439, k_q=26290, theta=8.628, psi=0.04321, beta_d=0 ) Exercise To help you better grasp what is going on in the model, redraw Fig. 7.1 on a chalkboard or a larger piece of paper and add as much detail as you can fit. Include model parameters and definitions and explanations – whatever helps you make sense of the processes, and their mathematical representation. 7.2 Implementing MEL Table 2 of Rastetter et al. also include initial values for the state variables, which we include here. init.states &lt;- c(Ec=350, En=1, # Inorganic nutrients g/m^2 Bc=22000, Bn=110, # Biomass nutrients g/m^2 Dc=13000, Dn=521, # Detritus nutrients g/m^2 Vc=0.5, Vn=0.5 # allocation &quot;effort&quot; unitless ) In addition to initial values of state variables, Rastetter, Agren, and Shaver (1997) (Table 2) list initial fluxes. We don’t have to worry about those; the model calculates the initial fluxes from parameters and from initial values of the state variables. 7.2.1 Increasing atmospheric carbon with events in ode() Rastetter et al. (1997) double CO\\(_2\\) concemntrations at an early time point in their simulations. We do that using an events in the ode() function. An “event” in an ode() model the value of a state variable changes suddenly at a one or more time points. In one sense, these are like ecological disturbances. For instance, we could add 1 kilogram of phosphorus to a lake in a one-time pulse, or halve primary producer biomass at 10 random times over a one hundred year interval. We can create events using either a function, or with a data frame. Here we create a data frame, using the required four variables: ‘var’ selects the state variable to change. ‘time’ is the time at which the event occurs. ‘value’ is the numeric value associated with the change. ‘method’ is the operator that operates on the ‘value’ and the state variable: ‘add’ will add the value to the state variable, ‘mult’ will multiply the state variable by the value, and ‘replace’ will simply replace the state variable with the value (the value can be a positive or negative number). event.df &lt;- data.frame(var=&quot;Ec&quot;, time=0.005, value=2, method=&quot;mult&quot;) This event will double atmospheric carbon concentration very shortly after the start of the simulation. We will run the model for 1000 years as in Rastetter et al. (1997), and specify that R return values for a logarithm series of time steps. ## 10^3 = 1000 years t=10^seq(-3, 3, by=.001) Next we run the model using parameters for a closed ecosystem, and a partly open system (Rastetter, Agren, and Shaver 1997). ## Closed ecosystem out.c &lt;- ode(init.states, t, func=mel2, parms=p.c, events=list(data=event.df) ) ## Partly open p.o &lt;- p.c p.o[&quot;Rne&quot;] &lt;- 1 p.o[&quot;beta_ne&quot;] &lt;- 1 out.o &lt;- ode(init.states, t, func=mel2, parms=p.o, events = list(data = event.df) ) You will probably get a warning message that R has included our event time into the integration procedure. That is a good thing. Next we convert the simulation data sets, add variables, combine, rearrange, and plot the results. out.c &lt;- out.c %&gt;% as.data.frame() %&gt;% mutate(N.cycle = &quot;closed&quot;) out.o &lt;- out.o %&gt;% as.data.frame() %&gt;% mutate(N.cycle = &quot;open&quot;) out.all &lt;- rbind(out.c, out.o) outL &lt;- pivot_longer(out.all, cols=-c(time, N.cycle), names_to=&quot;State_var&quot;, values_to=&quot;g.sq.m&quot;) ggplot(outL, aes(x=time, y=g.sq.m, colour=N.cycle)) + geom_line() + scale_x_log10() + facet_wrap(~State_var, ncol=3, scales=&quot;free&quot;) Figure 7.3: Simulated dynamics of carbon and nitrogen in an ecosystem with both C- and N-limitation, in a closed and partly open ecosystem. Recreates Fig. 3 from Rastetter et al. (1997), in part. Cool, right? Rastetter et al. introduce a couple terms that make my skin crawl, and I will do my best to explain them, and avoid them where I can.↩︎ "],["references.html", "8 References", " 8 References Bormann, F H, G E Likens, and J M Melillo. 1977. “Nitrogen budget for an aggrading northern hardwood forest ecosystem.” Science (New York, N.Y.) 196 (4293): 981–83. Carpenter, D R, C E Kraft, R Wright, X He, P A Soranno, and J R Hodgson. 1992. “Resilience and resistance of lake phosphorus cycle before and after food web manipulation.” Am. Nat. 140: 781–98. Chapin III, F. S., P. A. Matson, and P. M. Vitousek. 2011. Principles of Terrestrial Ecosystem Ecology. 2nd edition. Springer. Marquet, Pablo A., Andrew P. Allen, James H. Brown, Jennifer A. Dunne, Brian J. Enquist, James F. Gillooly, Patricia A. Gowaty, et al. 2014. “On theory in ecology.” BioScience 64 (8): 701–10. Rastetter, E. B., G. I. Agren, and G. R. Shaver. 1997. “Responses of n-Limited Ecosystems to Increased Co2: A Balanced-Nutrition, Coupled-Element-Cycles Model.” Ecological Applications 7 (2): 444–60. Rastetter, E. B., and G. R. Shaver. 1992. “A Model of Multiple-Element Limitation for Acclimating Vegetation.” Ecology 73 (4): 1157–74. https://doi.org/10.2307/1940666. Soetaert, K, and P M J Herman. 2009. A Practical Guide to Ecological Modelling. Springer. "]]
